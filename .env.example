# Deep Deer Configuration Example
# Copy this file to .env and update with your settings

# ============================================
# Server Configuration
# ============================================
HOST=0.0.0.0
PORT=8000
RELOAD=true
DEBUG=false

# ============================================
# Database Configuration
# ============================================
DATABASE_URL=sqlite+aiosqlite:///./deep_deer.db

# ============================================
# LLM Configuration
# ============================================
# Provider selection: ollama or huggingface_local
LLM_PROVIDER=ollama

# Ollama Settings (Server-based)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=gpt-oss:120b
OLLAMA_TIMEOUT=300

# HuggingFace Local Settings (Direct model loading)
# Enable to use HuggingFace models locally
ENABLE_HUGGINGFACE_LOCAL=false
# Can be any HuggingFace model: Qwen/Qwen3-0.6B, gpt2, meta-llama/Llama-2-7b-hf, etc.
HUGGINGFACE_LOCAL_MODEL=Qwen/Qwen3-0.6B
# Optional: HuggingFace token for downloading gated models
# HUGGINGFACE_TOKEN=your_token_here

# ============================================
# Embedding Configuration
# ============================================
# Provider selection: ollama or huggingface
EMBEDDING_PROVIDER=ollama

# Ollama Embedding Model
OLLAMA_EMBEDDING_MODEL=jeffh/intfloat-multilingual-e5-large-instruct:f32

# HuggingFace Embedding Model (used when EMBEDDING_PROVIDER=huggingface)
# Can be any HuggingFace embedding model including E5 instruct models
# E.g., BAAI/bge-m3, intfloat/multilingual-e5-large-instruct
EMBEDDING_MODEL=BAAI/bge-m3

# Enable lazy loading for embeddings (useful for large models)
ENABLE_LAZY_LOADING=false

# ============================================
# Vector Store Configuration
# ============================================
VECTOR_STORE_PATH=./vector_stores
CHUNK_SIZE=1000
CHUNK_OVERLAP=100

# ============================================
# Web Search Configuration
# ============================================
# Optional: Add your search API key if you have one
# SEARCH_API_KEY=your_api_key_here
MAX_SEARCH_RESULTS=10

# ============================================
# Security Configuration
# ============================================
# Change this in production!
SECRET_KEY=change-this-in-production
SENSITIVE_FIELDS=password,token,key,secret,credit_card,ssn,api_key

# ============================================
# LangChain Configuration
# ============================================
LANGCHAIN_VERBOSE=false
LANGCHAIN_CACHE=true

# ============================================
# Logging Configuration
# ============================================
LOG_LEVEL=INFO
# LOG_FILE=./logs/deep_deer.log