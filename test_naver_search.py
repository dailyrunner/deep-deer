#!/usr/bin/env python3
"""Test Naver Search API functionality"""
import asyncio
import logging
from app.services.web_search import web_searcher
from app.services.ollama_service import ollama_service
from app.services.langchain_pipeline import langchain_pipeline

logging.basicConfig(level=logging.INFO)

async def test_naver_search():
    """Test Naver search functionality"""
    print("ğŸ” Testing Naver Search API")
    print("=" * 50)

    # Initialize services
    await ollama_service.initialize()
    await web_searcher.initialize()
    await langchain_pipeline.initialize()

    # Test queries
    test_queries = [
        "AI ê³ ê° ì„œë¹„ìŠ¤ ìë™í™”",
        "ë¨¸ì‹ ëŸ¬ë‹ ì¶”ì²œ ì‹œìŠ¤í…œ",
        "ë¹…ë°ì´í„° ë¶„ì„ í”Œë«í¼",
        "chatbot development frameworks"
    ]

    for query in test_queries:
        print(f"\nğŸ“ Query: {query}")
        print("-" * 40)

        try:
            # Direct search test
            results = await web_searcher.search(query, max_results=5)

            if results:
                print(f"âœ… Found {len(results)} results:")
                for i, result in enumerate(results[:3], 1):
                    print(f"\n  {i}. {result.title[:80]}...")
                    print(f"     URL: {result.url}")
                    print(f"     Source: {result.source}")
                    print(f"     Snippet: {result.snippet[:100]}...")
                    if result.metadata:
                        print(f"     Type: {result.metadata.get('search_type', 'unknown')}")
            else:
                print("âŒ No results found")

        except Exception as e:
            print(f"âŒ Error: {e}")

    print("\n" + "=" * 50)
    print("ğŸ¯ Testing with keyword extraction and search")
    print("=" * 50)

    # Test with keyword extraction
    complex_query = "ìš°ë¦¬ íšŒì‚¬ì˜ ê³ ê° ë°ì´í„°ë¥¼ í™œìš©í•´ì„œ ê°œì¸í™”ëœ ë§ˆì¼€íŒ… ìº í˜ì¸ì„ ìë™í™”í•˜ëŠ” AI ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê³  ì‹¶ìŠµë‹ˆë‹¤"
    print(f"\nğŸ“ Complex Query: {complex_query}")

    from langchain.prompts import PromptTemplate
    from langchain.chains import LLMChain

    keyword_prompt = PromptTemplate(
        input_variables=["request"],
        template="""Extract 3-5 key search terms from this business request for web search.
Focus on technology terms, industry concepts, and market trends.
Avoid specific company names or internal details.

Request: {request}

Keywords (comma-separated):"""
    )

    keyword_chain = LLMChain(llm=langchain_pipeline.llm, prompt=keyword_prompt)
    result = await keyword_chain.ainvoke({"request": complex_query})
    keywords = result["text"].strip()

    print(f"âœ¨ Extracted keywords: {keywords}")

    # Search with extracted keywords
    results = await web_searcher.search(keywords, max_results=5)
    if results:
        print(f"\nğŸ“Š Found {len(results)} results for extracted keywords:")
        for i, result in enumerate(results[:2], 1):
            print(f"\n  {i}. {result.title[:80]}...")
            print(f"     Source: {result.source}")
    else:
        print("âŒ No results found for extracted keywords")

    # Cleanup
    await ollama_service.cleanup()
    await web_searcher.cleanup()

if __name__ == "__main__":
    asyncio.run(test_naver_search())